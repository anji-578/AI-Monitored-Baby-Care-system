{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WSOVBrtkAoma",
    "outputId": "19999c27-097a-44d2-fb85-49e233be237f"
   },
   "outputs": [],
   "source": [
    "#!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in c:\\users\\anjani janyavula\\anaconda3\\lib\\site-packages (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame\n",
    "from pygame import mixer\n",
    "import pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydub\n",
    "pydub.AudioSegment.converter = 'c:\\\\FFmpeg\\\\bin\\\\ffmpeg.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tXohUhR4-20Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in c:\\users\\anjani janyavula\\anaconda3\\lib\\site-packages (2.1.2)\n",
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anjani Janyavula\\anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import mediapipe\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dis\n",
    "!pip install pygame\n",
    "import pydub\n",
    "import pyttsx3\n",
    "import time\n",
    "import py\n",
    "import pydub\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "pydub.AudioSegment.converter = 'c:\\\\FFmpeg\\\\bin\\\\ffmpeg.exe'\n",
    "from pygame import mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Znk5vZrRAC-_"
   },
   "outputs": [],
   "source": [
    "def draw_landmarks(image, outputs, land_mark, color):\n",
    "    height, width = image.shape[:2]\n",
    "             \n",
    "    for face in land_mark:\n",
    "        point = outputs.multi_face_landmarks[0].landmark[face]\n",
    "        \n",
    "        point_scale = ((int)(point.x * width), (int)(point.y*height))\n",
    "        \n",
    "        cv.circle(image, point_scale, 2, color, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hAyvt8g8AFZN"
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(image, top, bottom):\n",
    "    height, width = image.shape[0:2]\n",
    "            \n",
    "    point1 = int(top.x * width), int(top.y * height)\n",
    "    point2 = int(bottom.x * width), int(bottom.y * height)\n",
    "    \n",
    "    distance = dis.euclidean(point1, point2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PlEnJREVAI7v"
   },
   "outputs": [],
   "source": [
    "def get_aspect_ratio(image, outputs, top_bottom, left_right):\n",
    "    landmark = outputs.multi_face_landmarks[0]\n",
    "            \n",
    "    top = landmark.landmark[top_bottom[0]]\n",
    "    bottom = landmark.landmark[top_bottom[1]]\n",
    "    \n",
    "    top_bottom_dis = euclidean_distance(image, top, bottom)\n",
    "    \n",
    "    left = landmark.landmark[left_right[0]]\n",
    "    right = landmark.landmark[left_right[1]]\n",
    "    \n",
    "    left_right_dis = euclidean_distance(image, left, right)\n",
    "    \n",
    "    aspect_ratio = left_right_dis/ top_bottom_dis\n",
    "    \n",
    "    return aspect_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countdown(t,rl):\n",
    "    \n",
    "    \n",
    "    \n",
    "    while t:\n",
    "        if(rl<1.8):\n",
    "            mins, secs = divmod(t, 60)\n",
    "            timer = '{:02d}:{:02d}'.format(mins, secs)\n",
    "            #print(timer, end=\"\\r\")\n",
    "            time.sleep(1)\n",
    "            t -= 1\n",
    "            \n",
    "            #if t == 0:\n",
    "                #print('Fire in the hole!!')\n",
    "                \n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        return(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WAy85nT8AMCT"
   },
   "outputs": [],
   "source": [
    "face_mesh = mp.solutions.face_mesh\n",
    "draw_utils = mp.solutions.drawing_utils\n",
    "landmark_style = draw_utils.DrawingSpec((0,255,0), thickness=1, circle_radius=1)\n",
    "connection_style = draw_utils.DrawingSpec((0,0,255), thickness=1, circle_radius=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "sy_Ez10FAOPw"
   },
   "outputs": [],
   "source": [
    "STATIC_IMAGE = False\n",
    "MAX_NO_FACES = 2\n",
    "DETECTION_CONFIDENCE = 0.6\n",
    "TRACKING_CONFIDENCE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "l0gRQaOYAQDP"
   },
   "outputs": [],
   "source": [
    "COLOR_RED = (0,0,255)\n",
    "COLOR_BLUE = (255,0,0)\n",
    "COLOR_GREEN = (0,255,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2PsObmLRAUl3"
   },
   "outputs": [],
   "source": [
    "LIPS=[ 61, 146, 91, 181, 84, 17, 314, 405, 321, 375,291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95,\n",
    "       185, 40, 39, 37,0 ,267 ,269 ,270 ,409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78 ]\n",
    "\n",
    "RIGHT_EYE = [ 33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246 ]\n",
    "LEFT_EYE = [ 362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385,384, 398 ]\n",
    "\n",
    "LEFT_EYE_TOP_BOTTOM = [386, 374]\n",
    "LEFT_EYE_LEFT_RIGHT = [263, 362]\n",
    "\n",
    "RIGHT_EYE_TOP_BOTTOM = [159, 145]\n",
    "RIGHT_EYE_LEFT_RIGHT = [133, 33]\n",
    "\n",
    "UPPER_LOWER_LIPS = [13, 14]\n",
    "LEFT_RIGHT_LIPS = [78, 308]\n",
    "\n",
    "\n",
    "FACE=[ 10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400,\n",
    "       377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103,67, 109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YImiZDxQAdrX"
   },
   "outputs": [],
   "source": [
    "face_model = face_mesh.FaceMesh(static_image_mode=STATIC_IMAGE,\n",
    "                                max_num_faces= MAX_NO_FACES,\n",
    "                                min_detection_confidence=DETECTION_CONFIDENCE,\n",
    "                                min_tracking_confidence=TRACKING_CONFIDENCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sleep detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "TxwaSKSEAgyk",
    "outputId": "0f0ec693-b4d3-4040-c495-a6edcc1e9548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baby is sleeping\n"
     ]
    }
   ],
   "source": [
    "capture = cv.VideoCapture(0)\n",
    "\n",
    "frame_count = 0\n",
    "min_frame = 6\n",
    "min_tolerance = 5.0\n",
    "\n",
    "speech = pyttsx3.init()\n",
    "\n",
    "t = 2\n",
    "mixer.init()\n",
    "\n",
    "while True:\n",
    "    result, image = capture.read()\n",
    "    \n",
    "    if result:\n",
    "        image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        outputs = face_model.process(image_rgb)\n",
    "\n",
    "        if outputs.multi_face_landmarks:\n",
    "           \n",
    "            draw_landmarks(image, outputs, FACE, COLOR_GREEN)\n",
    "               \n",
    "                \n",
    "            draw_landmarks(image, outputs, LEFT_EYE_TOP_BOTTOM, COLOR_RED)\n",
    "            draw_landmarks(image, outputs, LEFT_EYE_LEFT_RIGHT, COLOR_RED)\n",
    "            \n",
    "            ratio_left =  get_aspect_ratio(image, outputs, LEFT_EYE_TOP_BOTTOM, LEFT_EYE_LEFT_RIGHT)\n",
    "            \n",
    "    \n",
    "            draw_landmarks(image, outputs, RIGHT_EYE_TOP_BOTTOM, COLOR_RED)\n",
    "            draw_landmarks(image, outputs, RIGHT_EYE_LEFT_RIGHT, COLOR_RED)\n",
    "            \n",
    "            ratio_right =  get_aspect_ratio(image, outputs, RIGHT_EYE_TOP_BOTTOM, RIGHT_EYE_LEFT_RIGHT)\n",
    "            \n",
    "            ratio = (ratio_left + ratio_right)/2.0\n",
    "            \n",
    "            if ratio > min_tolerance:\n",
    "                frame_count +=1\n",
    "            else:\n",
    "                frame_count = 0\n",
    "                \n",
    "            if frame_count > min_frame and t > 0:\n",
    "                #Closing the eyes\n",
    "                speech.say('Baby is sleeping')\n",
    "                print(\"Baby is sleeping\")\n",
    "                speech.runAndWait()\n",
    "                time.sleep(4)\n",
    "                t -= 1\n",
    "                \n",
    "            if t == 0:\n",
    "                mixer.music.load('music.mp3')\n",
    "                mixer.music.play()\n",
    "                time.sleep(1)\n",
    "                t = 2\n",
    "                  \n",
    "            draw_landmarks(image, outputs, UPPER_LOWER_LIPS , COLOR_BLUE)\n",
    "            draw_landmarks(image, outputs, LEFT_RIGHT_LIPS, COLOR_BLUE)\n",
    "            mp_pose = mp.solutions.pose\n",
    "            pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "            results = pose.process(image)\n",
    "            \n",
    "            ratio_lips =  get_aspect_ratio(image, outputs, UPPER_LOWER_LIPS, LEFT_RIGHT_LIPS)\n",
    "            if ratio_lips < 1.2 and t > 0:\n",
    "                #Open his mouth   \n",
    "                mins, secs = divmod(t, 60)\n",
    "                timer = '{:02d}:{:02d}'.format(mins, secs)\n",
    "                #print(timer, end=\"\\r\")\n",
    "                speech.say('Drowsy Warning: You look tired.. please take rest')\n",
    "                speech.runAndWait()\n",
    "                time.sleep(1)\n",
    "                t -= 1\n",
    "                \n",
    "            if t == 0:\n",
    "                mixer.music.load('music.mp3')\n",
    "                mixer.music.play()\n",
    "                time.sleep(1)\n",
    "                t = 2\n",
    "           \n",
    "        cv.imshow(\"FACE MESH\", image)\n",
    "        if cv.waitKey(1) & 0xFF==ord(\"c\"):\n",
    "            break\n",
    "        \n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "results = pose.process(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hunger detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import math\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "mpPose = mp.solutions.pose\n",
    "pose = mpPose.Pose()\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "speech = pyttsx3.init()\n",
    "\n",
    "pTime = 0\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    image_height, image_width, _ = img.shape\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(imgRGB)\n",
    "    lm = results.pose_landmarks\n",
    "    lmPose  = mpPose.PoseLandmark\n",
    "    hunger=0\n",
    "\n",
    "    # print(results.pose_landmarks)\n",
    "    if results.pose_landmarks:\n",
    "        mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "        for id, lm in enumerate(results.pose_landmarks.landmark):\n",
    "            h, w, c = img.shape\n",
    "            cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "            cv2.circle(img, (cx, cy), 5, (255, 0, 0), cv2.FILLED)\n",
    "        x1=results.pose_landmarks.landmark[mpPose.PoseLandmark.MOUTH_RIGHT].x * image_width\n",
    "        y1=results.pose_landmarks.landmark[mpPose.PoseLandmark.MOUTH_RIGHT].y * image_height\n",
    "        x2=results.pose_landmarks.landmark[mpPose.PoseLandmark.RIGHT_THUMB].x * image_width\n",
    "        y2=results.pose_landmarks.landmark[mpPose.PoseLandmark.RIGHT_THUMB].y * image_height\n",
    "        dist=math.hypot(x1-x2,y1-y2)\n",
    "        if(dist<35):\n",
    "            speech.say('Baby is hungry')\n",
    "            speech.runAndWait()\n",
    "            hunger=hunger+20\n",
    "            print(\"Baby is Hungry\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    cTime = time.time()\n",
    "    fps = 1 / (cTime - pTime)\n",
    "    pTime = cTime\n",
    "    \n",
    "    \n",
    "    cv2.putText(img, str(int(hunger)), (150, 50), cv2.FONT_HERSHEY_PLAIN, 3,\n",
    "                (255, 0, 0), 3)\n",
    "\n",
    "    cv2.putText(img, str(int(fps)), (70, 50), cv2.FONT_HERSHEY_PLAIN, 3,\n",
    "                (255, 0, 0), 3)\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(1) & 0xFF==ord(\"c\"):\n",
    "        break\n",
    "        \n",
    "capture.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "import urllib\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "driver_path = 'C:\\Apps\\downloadchromedriver.exe'\n",
    "browser = webdriver.Chrome(driver_path)\n",
    "\n",
    "\n",
    "\n",
    "# Read .xlsx  file\n",
    "df = pd.read_excel('data.xlsx')\n",
    "for ind in df.index:\n",
    "    contact = df['Number'][ind]\n",
    "    txt_message = df['message'][ind]\n",
    "    \n",
    "\n",
    "    # visit Each Number\n",
    "    browser.get(f\"https://web.whatsapp.com/send?phone={contact}\")\n",
    "    \n",
    "\n",
    "    # Wait to Page load\n",
    "    while True:\n",
    "        try:\n",
    "           \n",
    "           input_box = browser.find_element(By.XPATH,'//*[@id=\"main\"]/footer/div[1]/div/span[2]/div/div[2]/div[1]/div/div[1]/p')\n",
    "           input_box.send_keys(txt_message)\n",
    "           time.sleep(2)\n",
    "           break\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Send message button Click\n",
    "    browser.find_element(By.XPATH,'//*[@id=\"main\"]/footer/div[1]/div/span[2]/div/div[2]/div[2]/button/span').click()    \n",
    "    time.sleep(5)\n",
    "\n",
    "    \n",
    "browser.close()    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sleeping Posture analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anjani janyavula\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anjani janyavula\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anjani janyavula\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anjani janyavula\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anjani janyavula\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anjani janyavula\\anaconda3\\lib\\site-packages)\n",
      "C:\\Users\\Anjani Janyavula\\anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in c:\\users\\anjani janyavula\\anaconda3\\lib\\site-packages (2.1.2)\n",
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "INDEX_FINGER_MCP",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2316\\758737817.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcircle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFILLED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m#SLEEPING POSTURE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mx1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmpPose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPoseLandmark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINDEX_FINGER_MCP\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mimage_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0my1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmpPose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPoseLandmark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINDEX_FINGER_MCP\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mimage_height\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mx2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmpPose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPoseLandmark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINDEX_FINGER_TIP\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mimage_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\enum.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_member_map_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: INDEX_FINGER_MCP"
     ]
    }
   ],
   "source": [
    "#Sleeping Posture analysis\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import math\n",
    "\n",
    "import mediapipe\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dis\n",
    "!pip install pygame\n",
    "import pyttsx3\n",
    "import time\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from pygame import mixer\n",
    "\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import urllib\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "mpPose = mp.solutions.pose\n",
    "pose = mpPose.Pose()\n",
    "cap = cv2.VideoCapture(0)\n",
    "speech = pyttsx3.init()\n",
    "\n",
    "\n",
    "pTime = 0\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    image_height, image_width, _ = img.shape\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(imgRGB)\n",
    "    lm = results.pose_landmarks\n",
    "    lmPose  = mpPose.PoseLandmark\n",
    "\n",
    "    # print(results.pose_landmarks)\n",
    "    if results.pose_landmarks:\n",
    "        mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "        for id, lm in enumerate(results.pose_landmarks.landmark):\n",
    "            h, w, c = img.shape\n",
    "            cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "            cv2.circle(img, (cx, cy), 5, (255, 0, 0), cv2.FILLED)\n",
    "        #SLEEPING POSTURE\n",
    "        x1=results.pose_landmarks.landmark[mpPose.PoseLandmark.MOUTH_RIGHT].x * image_width\n",
    "        y1=results.pose_landmarks.landmark[mpPose.PoseLandmark.MOUTH_RIGHT].y * image_height\n",
    "        x2=results.pose_landmarks.landmark[mpPose.PoseLandmark.MOUTH_LEFT].x * image_width\n",
    "        y2=results.pose_landmarks.landmark[mpPose.PoseLandmark.MOUTH_LEFT].y * image_height\n",
    "        dist_right=math.hypot(x1-x2,y1-y2)\n",
    "        if(dist_right<3):\n",
    "            speech.say('Baby is sleeping in wrong position')\n",
    "            speech.runAndWait()\n",
    "            print(\"Baby is sleeping in wrong position\")\n",
    "            \n",
    "        \n",
    "    cTime = time.time()\n",
    "    fps = 1 / (cTime - pTime)\n",
    "    pTime = cTime\n",
    "\n",
    "    cv2.putText(img, str(int(fps)), (70, 50), cv2.FONT_HERSHEY_PLAIN, 3,\n",
    "                (255, 0, 0), 3)\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv.waitKey(1) & 0xFF==ord(\"c\"):\n",
    "        break\n",
    "        \n",
    "capture.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiredness detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anjani Janyavula\\anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Requirement already satisfied: pygame in c:\\users\\anjani janyavula\\anaconda3\\lib\\site-packages (2.1.2)\n",
      "Baby is tired\n",
      "Baby is tired\n"
     ]
    }
   ],
   "source": [
    "##TiredNess\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import math\n",
    "import mediapipe\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dis\n",
    "\n",
    "import pyttsx3\n",
    "import time\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from pygame import mixer\n",
    "\n",
    "import pygame as pg\n",
    "from pygame import mixer\n",
    "pg.init()\n",
    "!pip install pygame\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "mpPose = mp.solutions.pose\n",
    "pose = mpPose.Pose()\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "frame_count = 0\n",
    "min_frame = 3\n",
    "t=4\n",
    "\n",
    "speech = pyttsx3.init()\n",
    "\n",
    "pTime = 0\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    image_height, image_width, _ = img.shape\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(imgRGB)\n",
    "    lm = results.pose_landmarks\n",
    "    lmPose  = mpPose.PoseLandmark\n",
    "\n",
    "    # print(results.pose_landmarks)\n",
    "    if results.pose_landmarks:\n",
    "        mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "        for id, lm in enumerate(results.pose_landmarks.landmark):\n",
    "            h, w, c = img.shape\n",
    "            cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "            cv2.circle(img, (cx, cy), 5, (255, 0, 0), cv2.FILLED)\n",
    "        xe=results.pose_landmarks.landmark[mpPose.PoseLandmark.LEFT_EYE].x * image_width\n",
    "        ye=results.pose_landmarks.landmark[mpPose.PoseLandmark.LEFT_EYE].y * image_height\n",
    "        xt=results.pose_landmarks.landmark[mpPose.PoseLandmark.LEFT_THUMB].x * image_width\n",
    "        yt=results.pose_landmarks.landmark[mpPose.PoseLandmark.LEFT_THUMB].y * image_height\n",
    "        dist_e=math.hypot(xe-xt,ye-yt)\n",
    "        if dist_e<60:\n",
    "                frame_count +=1\n",
    "        else:\n",
    "            frame_count = 0\n",
    "                \n",
    "        if frame_count > min_frame and t > 0:\n",
    "            #Closing the eyes\n",
    "            time.sleep(1)\n",
    "            t -= 1\n",
    "        if t == 0:\n",
    "            mixer.music.load('twinkle.mp3')\n",
    "            print(\"Baby is tired\")\n",
    "            mixer.music.play(-1)\n",
    "            time.sleep(1)\n",
    "            t = 2\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    cTime = time.time()\n",
    "    fps = 1 / (cTime - pTime)\n",
    "    pTime = cTime\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    cv2.putText(img, str(int(fps)), (70, 50), cv2.FONT_HERSHEY_PLAIN, 3,\n",
    "                (255, 0, 0), 3)\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(1) & 0xFF==ord(\"c\"):\n",
    "        break\n",
    "        \n",
    "capture.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Drowsiness Detection.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
